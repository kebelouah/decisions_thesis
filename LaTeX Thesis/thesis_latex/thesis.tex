\documentclass[diploma]{softlab-thesis}

%%%
%%%  Add and configure the packages that you need for your thesis
%%%

\usepackage{minted}
\usepackage{Times New Roman}
\usepackage{url}
\usepackage{breakurl}
\usepackage{graphicx}
\usepackage{amsmath} % Για μαθηματικούς τύπους
\usepackage{amssymb} % Για μαθηματικά σύμβολα


\sloppy

% Hyperref needs to be the last package to use!
\PassOptionsToPackage{hyphens}{url}
\usepackage[xetex,%
    pdfpagemode=UseOutlines,pdfstartview=FitW,%
    colorlinks=true,linkcolor=blue,citecolor=blue,urlcolor=blue,%
    bookmarks=true,bookmarksopen=true,bookmarksnumbered=false,%
    pdfencoding=auto,unicode=true,hyperfootnotes=true,%
    hypertexnames=false,%
  ]{hyperref}


%%%
%%%  The document
%%%

\begin{document}

%%%  Title page

\frontmatter

\title{Πρόβλεψη Δικαστικών Αποφάσεων}
\author{Θεόδωρος Άγγελος Μέξης}
\authoren{Theodoros Angelos Mexis}
\date{Φεβρουάριος 2025 }
\datedefense{15}{2}{2025}

\supervisor{Παναγιώτης Τσανάκας}
\supervisorpos{Καθηγητής Ε.Μ.Π.}

\committeeone{Νικόλαος Σ. Παπασπύρου}
\committeeonepos{Καθηγητής Ε.Μ.Π.}
\committeetwo{Πέτρος Παπαδόπουλος}
\committeetwopos{Επίκ. Καθηγητής Ε.Μ.Π.}
\committeethree{Γεώργιος Νικολάου}
\committeethreepos{Αν. Καθηγητής Ε.Κ.Π.Α.}

\TRnumber{CSD-SW-TR-42-17}  % number-year, ask nickie for the number
\department{Τομέας Τεχνολογίας Πληροφορικής και Υπολογιστών}

\maketitle


%%%  Abstract, in Greek

\begin{abstractgr}%

\begin{keywordsgr}
  Μηχανική Μάθηση,
  Τεχνητή Νοημοσύνη,
  Δικαστικές Αποφάσεις,
  Πρόβλεψη
\end{keywordsgr}
\end{abstractgr}


%%%  Abstract, in English

\begin{abstracten}%

\begin{keywordsen}

\end{keywordsen}
\end{abstracten}


%%%  Acknowledgements

\begin{acknowledgementsgr}
 Θα ήθελα να ευχαριστήσω τον επιβλέποντα καθηγητή μου Παναγιώτη Τσανάκα για την ευκαιρία που μου δόθηκε να εργαστώ στο εξαιρετικά ενδιαφέρον θέμα της διπλωματικής μου εργασίας. Οφείλω ένα τεράστιο ευχαριστώ στον Δρ. Μάριο Κόνιαρη, ο οποίος μου προσέφερε πραγματικά, κάθε δυνατή βοήθεια κατά την εκπόνηση της διπλωματικής μου εργασίας.
 Θα ήθελα επίσης να ευχαριστήσω την οικογένειά μου, τους φίλους και συμφοιτητές μου, που ήταν πλάι μου σε όλη την διάρκεια της φοιτητικής μου ζωής.
 Αφιερώνω την εργασία αυτή στον αδελφό μου Κωνσταντίνο.
\end{acknowledgementsgr}

\begin{acknowledgementsen}

\end{acknowledgementsen}


%%%  Various tables

\tableofcontents
%\listoftables
\listoffigures
%\listofalgorithms


%%%  Main part of the book

\mainmatter

\chapter{Εισαγωγή}

Η νομοθεσία αναπτύσσεται και εξελίσσεται συνεχώς για να ανταποκριθεί στις νέες και μεταβαλλόμενες ανάγκες των κοινωνιών, αντιδρώντας στις κοινωνικές, πολιτικές, οικονομικές και τεχνολογικές αλλαγές. Οι συνεχείς μεταβολές στη νομοθεσία και η ραγδαία αύξηση του αριθμού των δεδικασμένων υποθέσεων προσθέτουν ένα ολοένα αυξανόμενο βάρος στους νομικούς επαγγελματίες. Αυτό οδηγεί φυσικά στο ερώτημα αν μπορεί να παρασχεθεί κάποια μηχανική υποστήριξη στον τομέα αυτό. Ένα τέτοιο σύστημα θα διευκόλυνε τη δουλειά δικηγόρων, εισαγγελέων και δικαστών, καθώς και άλλων συναφών επαγγελματιών, και θα μπορούσε να έχει θετική συμβολή στο δημόσιο συμφέρον εξοικονομώντας χρόνο, μειώνοντας τα λάθη και βελτιώνοντας τη συνέπεια των δικαστικών αποφάσεων. Οι υπολογιστές μπορούν να αναλύσουν τεράστια σύνολα δεδομένα νομικών κειμένων.

\subsection{Νομικά Κείμενα}

Τα νομικά κείμενα είναι κείμενα τα οποία έχουν συνταχθεί για διάφορους σκοπούς, με βασικό τους χαρακτηριστικό ότι σχετίζονται με τον νόμο είτε λόγω της ιδιότητας του συντάκτη (π.χ δικαστής), είτε λόγω των αναφορών που περιέχουν σε άλλα νομικά κείμενα, ή λόγω της θεματολογίας τους που αφορά την ρύθμιση των δικαιωμάτων και των υποχρεώσεων ιδιωτών και θεσμών. Ορισμένοι από τους βασικούς τύπους νομικών κειμέναν, ιεραρχημένοι βάσει της ισχύος τους ως πηγών δικαίου, είναι οι παρακάτω :

\begin{enumerate}
\item \textbf{Συντάγματα} : τα οποία αποτελούν τις θεμελιώδεις ραχές που αφορούν πως διοικείται ένα κράτος.
\item \textbf{Νομοθεσία} : η οποία περιλαμβάνει τους νόμους τους οποίους θεσπίζει ένα νομοθετικό σώμα και ρυθμίζουν τι είναι επιτρεπτό από τον νόμο. Συνήθως, οι νόμοι οργανώνονται θεματικά σε κώδικες παρόμοιας θεματολογίας (π.χ Ποινικός Κώδικας).
\item \textbf{Δικαστικές Αποφάσεις} : οι οποίες περιλαμβάνουν τα ενδιάμεσα ή τελικά αποτελέσματα μιας δίκης, την κρίση του δικαστηρίου για τα γεγονότα και τα επιχειρήματα της κάθε πλευράς καθώς και την απόφαση του δικαστηρίου σε γραπτή μορφή.
\item \textbf{Συμβόλαια} : τα οποία συνιστούν αμοιβαίες συμφωνίες μεταξύ συμβαλλόμενων μερών, με σκοπό να τηρηθούν αμοιβαίες υποχρεώσεις.
\end{enumerate}

Τα νομικά κείμενα έχουν εξελιχθεί σημαντικά μέσα στις χιλιετίες που παρήλθαν από την πρώτη χρήση τους. Τα πρώτα κείμενα ιδιωτικού δικαίου ήταν συμβόλαια, διαθήκες και νομικές πράξεις εγγεγραμμένες σε πινακίδες από πηλό στην Σουμερία περίπου 5000 χρόνια πριν. Παρομοίως, τα πρώτα κείμενα δημοσίου δικαίου, όπως νόμοι, εμφανίστηκαν στην Μεσοποταμία µε τους νόμους του βασιλιά Ουρ Ναμμού και αργότερα τον κώδικα του Χαμουραμπί να αποτελούν γνωστά παραδείγματα. 

Στην Αρχαία Ελλάδα, οι νομικές ρυθμίσεις που αφορούσαν ιδιωτικές υποθέσεις, όπως θέματα
κληρονομιάς, εμπορίου και συμβολαίων, διακρίνονταν από τις διατάξεις που ρύθμιζαν τη ζωή των πολιτών σε κάθε πόλη-κράτος. Η νομοθεσία και οι νόρμες διέφεραν ανά περιοχή, κυρίως λόγω της επιρροής της ρητορικής τέχνης, της διάδοσης της γνώσης των νόμων και της λειτουργίας των δικαστηρίων, καθώς και άλλων κοινωνικοπολιτικών παραμέτρων που καθόριζαν την ιδιότητα του πολίτη. Εμβληματικά παραδείγματα περιλαμβάνουν τους αυστηρούς νόμους του Δράκοντα (620 π.Χ.), οι οποίοι αργότερα μεταρρυθμίστηκαν από τον Σόλωνα (593 π.Χ.), προσδίδοντας μια πιο ισορροπημένη προσέγγιση στη νομοθεσία.

\subsection{Δικαστήρια}




\chapter{Θεωρητικό υπόβαθρο}

\section{Τεχνικές Προβλέψεων}

\subsection{Ορισμός και Διαδικασία Πρόβλεψης}

Ως πρόβλεψη μπορεί να οριστεί η εκτίμηση αβέβαιων μελλοντικών γεγονότων. Οι προβλέψεις μπορούν να γίνουν βασισμένες στην εμπειρία και την παρατήρηση, σε στατιστικές μεθόδους, καθώς και σε πολύπλοκα μαθηματικά μοντέλα. Χρησιμοποιούνται για τη βελτίωση της λήψης αποφάσεων και σχεδιασμού. 

Η διαδικασία παραγωγής προβλέψεων είναι μια απαιτητική διαδικασία. Στην ακόλουθη παράγραφο θα περιγραφούν επιγραμματικά τα πέντε βασικά βήματα που είναι απαραίτητα για την παραγωγή και αξιολόγηση προβλέψεων:

\begin{enumerate}
    \item \textit{Καθορισμός του προβλήματος.} Συνιστά ένα από τα πιο σημαντικά και ταυτόχρονα δυσκολότερα μέρη της διαδικασίας παραγωγής προβλέψεων. Σε αυτό το βήμα γίνεται απόπειρα να καθοριστούν τα επιθυμητά μεγέθη που πρόκειται να προβλευθούν, καθώς και η μετέπειτα χρήση των προβλέψεων αυτών.
    \item \textit{Συλλογή των δεδομένων.} Η διαδικασία αυτή αποδεικνύεται συχνά χρονοβόρα, καθώς εκτός των μετρήσιμων αριθμητικών δεδομένων, σημαντική αποδεικνύεται και η χρήση διαθέσιμων εμπειρικών πληροφοριών για το αντικείμενο προς μελέτη. 
    \item \textit{Προεπεξεργασία των δεδομένων.} Ένα καίριο βήμα για την παραγωγή προβλέψεων συνιστά η απόκτηση μιας ολοκληρωμένης αίσθησης των διαθέσιμων δεδομένων, έτσι ώστε να εντοπιστούν πιθανά λάθη, ασυνήθιστες τιμές, σημαντικές τάσεις ή εποχικότητα. Σκοπός της προεπεξεργασίας των δεδομένων είναι η δημιουργία ενός εξομαλυμένου συνόλου δεδομένων για την εφαρμογή των μοντέλων πρόβλεψης.
     \item \textit{Επιλογή μεθόδων πρόβλεψης.} Επιτυγχάνεται η ορθή επιλογή μοντέλων πρόβλεψης καθώς και η ιδιαίτερα σημαντική διαδικασία επιλογής των κατάλληλων παραμέτρων τους, ώστε να παραχθούν τα πλέον ακριβή αποτελέσματα. 
      \item \textit{Χρήση και αξιολόγηση των μοντέλων πρόβλεψης.} Το τελικό στάδιο περιλαμβάνει την χρήση των επιλεγμένων μοντέλων ώστε να παραχθούν οι ζητούμενες προβλέψεις. Το κατά πόσο οι προβλέψεις των επιλεγμένων μοντέλων είναι ικανοποιητικές μπορεί να κριθεί μόνο με την πάροδο του χρόνου, και πιο συγκεκριμένα καθώς τα νέα δεδομένα γίνονται διαθέσιμα. Η αξιολόγηση και η μέτρηση της ακρίβειας των προβλέψεων επιτυγχάνεται με εξειδικευμένους στατιστικούς δείκτες.
\end{enumerate}

\subsection{Κατηγορίες Μεθόδων Πρόβλεψης}

Οι μέθοδοι πρόβλεψης, σύμφωνα με την διαδικασία παραγωγής τους, διακρίνονται σε τρεις μεγάλες κατηγορίες :
\begin{enumerate}
\item \textbf{Ποσοτικές Μέθοδοι}. Οι ποσοτικές μέθοδοι αναφέρονται στην εφαρμογή στατιστικών μοντέλων χρονοσειρών ή αιτιοκρατικών μοντέλως επί μιας σειρά δεδομένων με σκοπό αυτοματοποιημένη και συστηματική παραγωγή προβλέψεων. Οι στατιστικές προβλέψεις είναι αποδεκτά ακριβείς και εφαρμόσιμες, αν συνδυαστούν με κατάλληλα διαστήματα εμπιστοσύνης. Προϋποθέτουν ότι η συμπεριφορά της εκάστοτε χρονοσειράς θα συνεχιστεί στο μέλλον, κάτι το οποίο δεν συμβαίνει πάντα. Επιπροσθέτως, κύρια παραδοχή των μοντέλων αυτών συνιστά η σταθερή συσχέτιση μεταξύ του προς πρόβλεψη μεγέθους και άλλων παραγόντων, χωρίς ωστόσο να είναι απαραίτητ η ύπαρξη χρονική εξάρτησης. Η συλλογή των δεδομένων αποτελεί συχνά μια χρονοβόρα και ενίοτε δύσκολη διαδικασία, καθώς απαιτείται μεγ
άλο πλήθος ιστορικών δεδομένων προκειμένουν να παραχθούν οι ζητούμενες προβλέψεις. Τέτοια μοντέλα είναι οι μέθοδοι εκθετικής εξομάλυνσης, τα μοντέλα παλινδρόμησης, τα μοντέλα ARIMA και τα τεχνητά νευρωνικά δίκτυα. 
\item \textbf{Κριτικές Μέθοδοι}. Οι κριτικές μέθοδοι πρόβλεψης δεν έχουν τις ίδιες απαιτήσεις σε
δεδομένα όπως οι στατιστικές μέθοδοι. Τα δεδομένα των κριτικών μεθόδων αποτελούν προϊόν διαίσθησης, κρίσης και συσσωρευμένης γνώσης από πλευράς εμπειρογνωμόνων. Οι μέθοδοι αυτές μπορούν να λάβουν υπόψη ειδικά γεγονότα και ενέργειες, ενώ ταυτόχρονα έχουν τη δυνατότητα να αντισταθμίζουν ανεπάρκειες και ελλείψεις σε ιστορικά δεδομένα. Είναι κατάλληλες όταν θίγονται ηθικά ζητήματα που υπερισχύουν των οικονομικών και τεχνολογικών παραγόντων. Οι μέθοδοι αυτές πρέπει να λειτουργούν συμπληρωματικά με τις μεθόδους στατιστικής μελέτης. Ανάμεσα στις πιο διαδεδομένες μεθόδους συγκαταλέγονται η απλή κρίση, η μέθοδος Delphi και οι δομημένες αναλογίες.
\item \textbf{Τεχνολογικές Μέθοδοι}. Οι τεχνολογικές μέθοδοι πρόβλεψης αφορούν κυρίως μακροπρόθεσμα πλάνα τεχνολογικής, οικονομικής, κοινωνικής και πολιτικής φύσης. Διακρίνονται σε διερευνητικές και κανονιστικές. Οι πρώτες έχουν ως σημείο εκκίνησης το παρελθόν και το παρόν και στοχεύουν στη διερεύνηση όλων των πιθανών μελλοντικών περιπτώσεων. Οι κανονιστικές έχουν προκαθορισμένους στόχους και εξετάζουν τη δυνατότητα επίτευξής τους, σύμφωνα με τους υπάρχοντες περιορισμούς και διαθέσιμους πόρους [Φ13].
\end{enumerate}

\subsection{Μηχανική Μάθηση}

Η μηχανική μάθηση είναι υποπεδίο της επιστήμης των υπολογιστών που αναπτύχθηκε από τη μελέτη της αναγνώρισης προτύπων και της υπολογιστικής θεωρίας μάθησης στην τεχνητή νοημοσύνη. Η μηχανική μάθηση διερευνά τη μελέτη και την κατασκευή αλγορίθμων που μπορούν να μαθαίνουν από τα δεδομένα και να κάνουν προβλέψεις σχετικά με αυτά. Οι αλγόριθμοι αυτοί βελτιώνουν τη συμπεριφορά τους σε κάποια εργασία χρησιμοποιώντας την εμπειρία τους. Τέτοιοι αλγόριθμοι λειτουργούν κατασκευάζοντας μοντέλα από πειραματικά δεδομένα, προκειμένου να κάνουν προβλέψεις βασιζόμενες στα δεδομένα ή να εξάγουν αποφάσεις που εκφράζονται ως το αποτέλεσμα. Ο Άρθουρ Σάμουελ ορίζει τη μηχανική μάθηση ως \textit{"Πεδίο μελέτης που δίνει στους υπολογιστές την ικανότητα να μαθαίνουν, χωρίς να έχουν ρητά προγραμματιστεί"}.

Ο τομέας της μηχανικής μάθησης αναπτύσσει τρεις τρόπους μάθησης, ανάλογους με
τους τρόπους με τους οποίους μαθαίνει ο άνθρωπος:
\begin{enumerate}
\item \textbf{Επιβλεπόμενη μάθηση} \textit{(Supervised Learning)}. Η επιβλεπόμενη μάθηση είναι η διαδικασία όπου ο αλγόριθμος κατασκευάζει μια συνάρτηση που απεικονίζει δεδομένες εισόδους
(σύνολο εκπαίδευσης) σε γνωστές επιθυμητές εξόδους, με απώτερο στόχο τη γενίκευση της
συνάρτησης αυτής και για εισόδους με άγνωστη έξοδο. Χρησιμοποιείται σε προβλήματα
ταξινόμησης (classification), πρόγνωσης (prediction) και διερμηνείας (interpretation).
\item \textbf{Μη επιβλεπόμενη μάθηση} \textit{(Unsupervised Learning)}. Στην μη επιβλεπόμενη μάθηση ο
αλγόριθμος κατασκευάζει ένα μοντέλο για κάποιο σύνολο εισόδων υπό μορφή
παρατηρήσεων χωρίς να γνωρίζει τις επιθυμητές εξόδους. Χρησιμοποιείται σε προβλήματα
ανάλυσης συσχετισμών (association analysis) και ομαδοποίησης (clustering).
\item \textbf{Ενισχυτική μάθηση}
 \textit{(Reinforcement Learning)}. Στην ενισχυτική μάθηση ο αλγόριθμος
μαθαίνει μια στρατηγική ενεργειών μέσα από άμεση αλληλεπίδραση με το περιβάλλον.
Χρησιμοποιείται κυρίως σε προβλήματα σχεδιασμού, όπως ο έλεγχος κίνησης ρομπότ και η
βελτιστοποίηση εργασιών σε εργοστασιακούς χώρους.
\end{enumerate}

\section{Μοντέλα Πρόβλεψης - Ταξινόμησης}

Στην παρούσα ενότητα παρουσιάζονται τα μοντέλα μηχανικής μάθησης που δοκιμάστηκαν στο πρόβλημα της πρόβλεψης δικαστικών αποφάσεων.

%Οι πιο γνωστές και χρήσιμες μέθοδοι για την πρόβλεψη έκβασης δικαστικών αποφάσεων -βάσει της βιβλιογραφίας- είναι τα Δέντρα Αποφάσεων (\textit{Decision Trees}), τα Τυχαία Δάση (\textit{Random  Forest}), οι Μηχανές Υποστήριξης Διανυσμάτων ((\textit{SVMs}) καθώς και η Γραμμική Παλινδρόμηση (\textit{Linear Regression}). 

\subsection{Δέντρα Αποφάσεων - Decision Trees}

Τα δέντρα αποφάσεων (decision trees) είναι ένας δημοφιλής και διαισθητικός αλγόριθμος μηχανικής μάθησης που χρησιμοποιείται για προβλήματα ταξινόμησης και παλινδρόμησης. Πρόκειται για μια δενδροειδή δομή όπου τα δεδομένα χωρίζονται διαδοχικά με βάση τα χαρακτηριστικά τους, με στόχο την κατηγοριοποίηση ή την πρόβλεψη μιας τιμής.

\begin{enumerate}
\item Ένα δέντρο αποφάσεων αποτελείται από κόμβους και κλάδους. Ο πρώτος κόμβος (ριζικός κόμβος) είναι ο κόμβος από τον οποίο ξεκινά η ανάλυση των δεδομένων. Στη συνέχεια, κάθε κόμβος διασπάται με βάση τις τιμές ενός χαρακτηριστικού, δημιουργώντας δύο ή περισσότερους υποκόμβους. Οι τελικοί κόμβοι, γνωστοί ως φύλλα, περιέχουν την τελική απόφαση (την κατηγορία ή την τιμή) που αντιστοιχεί στο εκάστοτε δείγμα.
\item Η επιλογή των χαρακτηριστικών που χρησιμοποιούνται για τη διάσπαση κάθε κόμβου γίνεται με βάση κριτήρια που βελτιστοποιούν την ποιότητα της διάσπασης. Στην ταξινόμηση, τα πιο κοινά κριτήρια είναι:
\begin{enumerate}
\item{Δείκτης Gini}: Μετρά την ακαθαρσία (impurity) του κόμβου. Η τιμή του κυμαίνεται μεταξύ 0 (όλα τα δείγματα του κόμβου ανήκουν στην ίδια κατηγορία) και 0,5 (τα δείγματα κατανέμονται εξίσου μεταξύ δύο κατηγοριών).
\item{Εντροπία}: Μετρά την αβεβαιότητα ή την ανομοιογένεια του κόμβου. Στόχος είναι η ελαχιστοποίηση της εντροπίας σε κάθε διάσπαση.
\item{Παλινδρόμηση}: στην παλινδρόμηση, η διάσπαση συνήθως βασίζεται στη μέση τετραγωνική απόκλιση ή στο σφάλμα παλινδρόμησης, όπου η μέθοδος προσπαθεί να ελαχιστοποιήσει την απόκλιση μεταξύ της προβλεπόμενης και της πραγματικής τιμής.
\end{enumerate}
\item Δημιουργία του Δέντρου: Το δέντρο αποφάσεων δημιουργείται αναδρομικά, με κάθε διάσπαση να αυξάνει το βάθος του δέντρου και να διαιρεί τα δεδομένα σε μικρότερα και πιο ομοιογενή υποσύνολα. Η διαδικασία συνεχίζεται μέχρι να επιτευχθούν ορισμένα κριτήρια τερματισμού, όπως:
\begin{enumerate}
\item Όλοι οι κόμβοι έχουν το ίδιο χαρακτηριστικό ή είναι αρκετά καθαροί.
\item Έχει φτάσει το μέγιστο προκαθορισμένο βάθος του δέντρου.
\item Κάθε κόμβος έχει λιγότερα από έναν ελάχιστο αριθμό δεδομένων.
\end{enumerate}
\item Καθώς τα δέντρα αποφάσεων τείνουν να υπερεκπαιδεύονται, εφαρμόζεται μια τεχνική που ονομάζεται κλάδεμα (pruning). Το κλάδεμα απομακρύνει τους κόμβους που δεν προσφέρουν σημαντικές βελτιώσεις στην ακρίβεια, μειώνοντας το βάθος του δέντρου και βελτιώνοντας τη γενική του ικανότητα.
\item Τα δέντρα αποφάσεων είναι εύκολα στην κατανόηση και την ερμηνεία, καθώς η ιεραρχική διαδικασία διάσπασης είναι διαισθητική. Έχουν χαμηλό υπολογιστικό κόστος και είναι κατάλληλα για προβλήματα με πολλά χαρακτηριστικά, καθώς και για διαχείριση δεδομένων με ελλείψεις.
\item 

Τα δέντρα αποφάσεων τείνουν να υπερεκπαιδεύονται στα δεδομένα εκπαίδευσης, ειδικά αν το δέντρο δεν κλαδευτεί. Αυτό οδηγεί σε χαμηλή γενική ικανότητα και απόδοση σε νέα δεδομένα. Επιπλέον, είναι ευαίσθητα στις αλλαγές στα δεδομένα (π.χ., μια μικρή αλλαγή μπορεί να αλλάξει σημαντικά τη δομή του δέντρου).
\end{enumerate}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/dectrees.png} % Adjust the width as needed
    \caption{Μοντέλο Δέντρων Απόφασης}
    \label{fig:your_image_label}
\end{figure}


\subsection{Τυχαία Δάση - Random Forests}

Τα τυχαία δάση (Random Forests) είναι ένας από τους πιο δημοφιλείς αλγόριθμους μηχανικής μάθησης, ιδιαίτερα για προβλήματα ταξινόμησης και παλινδρόμησης. Αναπτύχθηκαν από τον Leo Breiman το 2001 \cite{1} και βασίζονται σε μια προσέγγιση σύνολου (\textit{ensemble learning}), δηλαδή συνδυάζουν πολλά ανεξάρτητα μοντέλα (\textit{δέντρα αποφάσεων}) για να βελτιώσουν την ακρίβεια των προβλέψεων και να μειώσουν την πιθανότητα υπερεκπαίδευσης. 

\begin{enumerate}
\item Κάθε τυχαίο δάσος αποτελείται από έναν αριθμό δέντρων αποφάσεων. Το δέντρο αποφάσεων (decision tree) είναι ένα μοντέλο που δημιουργεί μια σειρά από κανόνες, οι οποίοι βασίζονται στις τιμές των χαρακτηριστικών ενός δείγματος, για να καταλήξει σε μια απόφαση (π.χ., την κατηγορία στην οποία ανήκει το δείγμα ή την πρόβλεψη τιμής). Ωστόσο, τα δέντρα αποφάσεων έχουν την τάση να υπερεκπαιδεύονται, δηλαδή να προσαρμόζονται υπερβολικά στα δεδομένα εκπαίδευσης, μειώνοντας έτσι τη γενική ικανότητά τους σε νέα δεδομένα.
\item Τα τυχαία δάση καταπολεμούν το πρόβλημα της υπερεκπαίδευσης συνδυάζοντας πολλαπλά δέντρα, καθένα από τα οποία εκπαιδεύεται σε διαφορετικό υποσύνολο των δεδομένων εκπαίδευσης. Ο αλγόριθμος χρησιμοποιεί την τεχνική του bootstrap aggregation (ή bagging), δηλαδή επιλέγει τυχαία, με επανάληψη, ένα υποσύνολο των δεδομένων για την εκπαίδευση κάθε δέντρου. Αυτό βοηθά να δημιουργηθούν πιο ανεξάρτητα δέντρα και μειώνει την πιθανότητα υπερεκπαίδευσης.
\item Σε κάθε κόμβο ενός δέντρου στο τυχαίο δάσος, ο αλγόριθμος εξετάζει ένα τυχαίο υποσύνολο χαρακτηριστικών, αντί για όλα τα διαθέσιμα χαρακτηριστικά, για να επιλέξει την καλύτερη διάσπαση. Αυτή η τυχαιότητα επιτρέπει τη δημιουργία δέντρων που είναι πιο διαφοροποιημένα μεταξύ τους και βελτιώνει τη γενική ικανότητα του μοντέλου.
\item Συνδυασμός Αποφάσεων: Στο τέλος, το τυχαίο δάσος συνδυάζει τις προβλέψεις από κάθε δέντρο για να παράγει την τελική απόφαση. Στην ταξινόμηση, γίνεται με ψηφοφορία πλειοψηφίας (majority voting), όπου η τελική πρόβλεψη είναι η κατηγορία που επιλέγεται πιο συχνά από τα δέντρα. Στην παλινδρόμηση, η τελική πρόβλεψη είναι ο μέσος όρος των προβλέψεων όλων των δέντρων.
\item  Τα τυχαία δάση είναι ανθεκτικά στην υπερεκπαίδευση, ειδικά για μεγάλα σύνολα δεδομένων με υψηλή διαστατικότητα. Έχουν υψηλή ακρίβεια και μπορούν να χρησιμοποιηθούν για την εκτίμηση της σημασίας των χαρακτηριστικών, πράγμα που είναι πολύτιμο σε προβλήματα όπου χρειάζεται να κατανοήσουμε ποια χαρακτηριστικά έχουν μεγαλύτερη επιρροή.
\item Ένα από τα κύρια μειονεκτήματα των τυχαίων δασών είναι ότι απαιτούν περισσότερους υπολογιστικούς πόρους, ιδιαίτερα για μεγάλα σύνολα δεδομένων, και είναι πιο δύσκολο να ερμηνευτούν σε σχέση με απλούστερα μοντέλα.
\end{enumerate}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/randfor} % Adjust the width as needed
    \caption{Μοντέλο Τυχαίων Δασών}
    \label{fig:your_image_label}
\end{figure}

\subsection{XGBoost Regression}

Η μέθοδος XGBoost είναι η συντομογραφία του Extreme Gradient Boosting και αποτελεί επίσης έναν αλγόριθμο ενίσχυσης. Με τον όρο ενίσχυση (boosting), εννοείται μια οικογένεια αλγορίθμων συνδυασμού μοντέλων, οι οποίες αποσκοπούν στη μετατροπή αδύναμων μοντέλων με χαμηλή απόδοση, σε ισχυρά μοντέλα πρόβλεψης. Οι αλγόριθμοι αυτοί βρίσκουν εφαρμογή τόσο σε προβλήματα ταξινόμησης, όσο
και παλινδρόμησης. Η μέθοδος Gradient Boosting, αποτελεί μια ισχυρή τεχνική συνδυασμού αδύναμων μοντέλων, με στόχο τη δημιουργία ενός ισχυρότερου. Αρχικά, εκπαιδεύεται ένα μοντέλο σε ένα υποσύνολο των δεδομένων εκπαίδευσης. Χρησιμοποιώντας αυτό το μοντέλο, γίνονται προβλέψεις σε ολόκληρο το σύνολο δεδομένων εκπαίδευσης και υπολογίζεται το σφάλμα του. Αυτές οι προβλέψεις είναι ανεπαρκείς και το αδύναμο μοντέλο θα πρέπει να ενισχυθεί σε μεταγενέστερες επαναλήψεις. Αυτός είναι ο λόγος για τον οποίον δημιουργείται ένα νέο μοντέλο, λαμβάνοντας υπόψη, τα σφάλματα που υπολογίστηκαν πριν, προκειμένου να διορθώσει τα λάθη του πρώτου. Τέλος, οι προβλέψεις του νέου μοντέλου συνδυάζονται με του προηγούμενου. 

Το XGBoost υποστηρίζει πολλές τεχνικές για την ενίσχυση της απόδοσής του:
\begin{itemize}
\item Early stopping: Σταματά την εκπαίδευση όταν η απόδοση στο σύνολο επικύρωσης δεν βελτιώνεται μετά από έναν ορισμένο αριθμό επαναλήψεων.
\item Feature importance: Προσφέρει εργαλεία για την ανάλυση της σημασίας των χαρακτηριστικών, ώστε να μπορούμε να εντοπίσουμε ποια χαρακτηριστικά συμβάλλουν περισσότερο στις προβλέψεις.
\item Regularization: Περιλαμβάνει L1 (Lasso) και L2 (Ridge) κανονικοποίηση για την πρόληψη υπερεκπαίδευσης.
\item Parallellization: Εκμεταλλεύεται την παραλληλία για να επιταχύνει τη διαδικασία εκπαίδευσης.
\end{itemize}


Η επιλογή παραμέτρων, όπως ο αριθμός των δέντρων, το μέγιστο βάθος κάθε δέντρου, η μάθηση ρυθμού (\textit{learning rate}), και η ελάχιστη απώλεια μείωσης (\textit{min child weight}), επηρεάζουν σημαντικά την απόδοση του XGBoost. Το XGBoost θεωρείται ένας από τους πιο ισχυρούς αλγόριθμους, ιδιαίτερα σε προβλήματα με μεγάλα και πολύπλοκα δεδομένα.

Ωστόσο, λόγω της πολυπλοκότητάς του, μπορεί να είναι υπολογιστικά απαιτητικό και να χρειάζεται προσεκτική ρύθμιση των παραμέτρων για την επίτευξη της καλύτερης απόδοσης.


\subsection{Μηχανές Υποστήριξης Διανυσμάτων - SVM}

Οι Υποστηρικτικές Μηχανές Διανυσμάτων (Support Vector Machines - SVM) είναι ένας ισχυρός αλγόριθμος μηχανικής μάθησης για ταξινόμηση και παλινδρόμηση. Η βασική ιδέα του SVM είναι η εύρεση μιας υπερ-επιφάνειας (ή υπερ-επίπεδου) που διαχωρίζει με τον καλύτερο δυνατό τρόπο τα δεδομένα σε κατηγορίες.

\begin{enumerate}
\item Ένα υπερ-επίπεδο είναι ένας γραμμικός διαχωριστής σε έναν χώρο δεδομένων πολλών διαστάσεων. Στην SVM, επιδιώκεται να βρεθεί το υπερ-επίπεδο που διαχωρίζει τα δεδομένα με το μέγιστο περιθώριο (maximum margin), δηλαδή το υπερ-επίπεδο που βρίσκεται όσο το δυνατόν πιο μακριά από τα σημεία των δύο κατηγοριών. Αυτό το περιθώριο επιτρέπει στο μοντέλο να έχει καλύτερη γενική ικανότητα και να αντέχει στις αλλαγές των δεδομένων.
\item Τα σημεία που βρίσκονται πλησιέστερα στο υπερ-επίπεδο διαχωρισμού ονομάζονται διανύσματα υποστήριξης (support vectors). Αυτά τα διανύσματα είναι τα πιο κρίσιμα δεδομένα για την εκπαίδευση του μοντέλου, καθώς η θέση τους καθορίζει το μέγιστο περιθώριο και την τελική θέση του υπερ-επιπέδου. Αν αλλάξουν αυτά τα σημεία, αλλάζει και το υπερ-επίπεδο διαχωρισμού.
\item Η βασική SVM είναι γραμμική, πράγμα που σημαίνει ότι χρησιμοποιεί έναν γραμμικό διαχωριστή για την ταξινόμηση των δεδομένων. Ωστόσο, σε πολλά προβλήματα τα δεδομένα δεν είναι γραμμικά διαχωρίσιμα. Για να αντιμετωπιστεί αυτό, η SVM χρησιμοποιεί τον πυρήνα (kernel trick), δηλαδή έναν μετασχηματισμό που επιτρέπει τη μετατροπή των δεδομένων σε έναν χώρο υψηλότερων διαστάσεων, όπου τα δεδομένα γίνονται γραμμικά διαχωρίσιμα.
\item Η επιλογή του κατάλληλου πυρήνα εξαρτάται από τη φύση των δεδομένων. Οι πιο συνηθισμένοι πυρήνες είναι:
\begin{enumerate}
\item{\textbf{Γραμμικός πυρήνας}}: Χρησιμοποιείται όταν τα δεδομένα είναι γραμμικά διαχωρίσιμα.
\item{\textbf{Πολυωνυμικός πυρήνας}}: Κατάλληλος για μη γραμμικές σχέσεις.
\item {\textbf{Πυρήνας Radial Basis Function (RBF)}}: Είναι από τους πιο διαδεδομένους για μη γραμμικά δεδομένα και χρησιμοποιείται συχνά όταν τα δεδομένα έχουν πολύπλοκες σχέσεις.
\item {\textbf{Πυρήνας Sigmoid}}: Χρησιμοποιείται σπανιότερα αλλά μπορεί να έχει εφαρμογές σε συγκεκριμένες περιπτώσεις.
\end{enumerate}
\item Παράμετροι C και γ (\textit{Gamma}): Οι δύο κύριες παράμετροι που ρυθμίζουν την απόδοση της SVM είναι οι παράμετροι C και γ.
\begin{enumerate}
\item Παράμετρος C: Ρυθμίζει το μέγεθος του περιθωρίου του υπερ-επιπέδου διαχωρισμού. Μια υψηλή τιμή του C μειώνει το περιθώριο, προσπαθώντας να ταξινομήσει όλα τα δεδομένα σωστά. Αυτό μπορεί να οδηγήσει σε υπερεκπαίδευση. Μια χαμηλή τιμή του C αυξάνει το περιθώριο, αλλά μπορεί να επιτρέψει κάποια σφάλματα ταξινόμησης.
\item Παράμετρος γ: Στους πυρήνες RBF και πολυωνυμικού τύπου, η παράμετρος γ καθορίζει την επίδραση των μεμονωμένων δεδομένων στο διαχωριστικό υπερ-επίπεδο. Χαμηλές τιμές του γ κάνουν το μοντέλο να έχει πιο ευρύχωρες καμπύλες, ενώ υψηλές τιμές του γ κάνουν το μοντέλο να προσαρμόζεται στενά στα δεδομένα.
\end{enumerate}
\item Η SVM είναι πολύ αποτελεσματική σε περιπτώσεις όπου τα δεδομένα έχουν σαφή διαχωριστικά όρια και είναι ιδανική για προβλήματα υψηλής διαστατικότητας. Είναι ανθεκτική στην υπερεκπαίδευση, ειδικά όταν χρησιμοποιείται με το κατάλληλο πυρήνα.
\item Η SVM μπορεί να είναι υπολογιστικά απαιτητική, ιδιαίτερα για μεγάλα σύνολα δεδομένων. Επίσης, η επιλογή του κατάλληλου πυρήνα και των παραμέτρων είναι δύσκολη και απαιτεί πειραματισμό. Σε προβλήματα όπου οι κατηγορίες δεν είναι καθαρά διαχωρίσιμες, η SVM μπορεί να παρουσιάσει υποδεέστερη απόδοση σε σχέση με άλλες μεθόδους.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/svm.png} % Adjust the width as needed
    \caption{Support Vector Machines}
    \label{fig:your_image_label}
\end{figure}


\subsection{Γραμμική Παλινδρόμηση - Linear Regression}

Η γραμμική παλινδρόμηση είναι ένας απλός και ευρέως χρησιμοποιούμενος αλγόριθμος μηχανικής μάθησης που χρησιμοποιείται για την πρόβλεψη μιας συνεχούς εξαρτημένης μεταβλητής (στόχου) από μία ή περισσότερες ανεξάρτητες μεταβλητές (χαρακτηριστικά). Ο αλγόριθμος επιδιώκει να βρει την καλύτερη δυνατή γραμμική σχέση ανάμεσα στην εξαρτημένη και τις ανεξάρτητες μεταβλητές.
\begin{enumerate}
\item Στη γραμμική παλινδρόμηση, το μοντέλο περιγράφεται από τη γραμμική εξίσωση:
\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \varepsilon
\]
όπου: 
\begin{itemize}
\item y  είναι η εξαρτημένη μεταβλητή (η πρόβλεψη).
\item \( x_1, x_2, \dots, x_n \) είναι οι ανεξάρτητες μεταβλητές.
\item \beta_0  είναι το σταθερό όρο (intercept).
\item \( \beta_1, \beta_2, \dots, \beta_n \) είναι οι συντελεστές παλινδρόμησης (coefficients) για κάθε ανεξάρτητη μεταβλητή, οι οποίοι υποδεικνύουν το μέγεθος και την κατεύθυνση της επίδρασης κάθε ανεξάρτητης μεταβλητής στην εξαρτημένη μεταβλητή.
\item ε είναι το σφάλμα (error term), που αντιπροσωπεύει τη διαφορά μεταξύ των πραγματικών και των προβλεπόμενων τιμών.
\end{itemize}

\item Ανάλυση και Εκτίμηση των Συντελεστών: Οι συντελεστές εκτιμώνται με τη μέθοδο ελαχίστων τετραγώνων (\texit{Ordinary Least Squares - OLS}). Η μέθοδος αυτή επιλέγει τις τιμές των συντελεστών που ελαχιστοποιούν το άθροισμα των τετραγωνικών διαφορών (σφαλμάτων) μεταξύ των πραγματικών και των προβλεπόμενων τιμών:

\text{Ελαχιστοποίηση του } \sum (y_{\text{πραγματικό}} - y_{\text{πρόβλεψη}})^2

Αυτή η προσέγγιση εξασφαλίζει ότι το μοντέλο είναι η βέλτιστη γραμμική προσέγγιση των δεδομένων.

\item Υποθέσεις της γραμμικής παλινδρόμησης :
\begin{enumerate}

\item{Γραμμικότητα}: Υπάρχει γραμμική σχέση μεταξύ των ανεξάρτητων μεταβλητών και της εξαρτημένης μεταβλητής.
\item{Κανονικότητα των Σφαλμάτων}: Τα σφάλματα ακολουθούν κανονική κατανομή με μέσο όρο 0.
\item{Ομοσκεδαστικότητα}: Η διασπορά των σφαλμάτων είναι σταθερή για όλες τις τιμές των ανεξάρτητων μεταβλητών (δηλαδή, δεν αλλάζει ανάλογα με την τιμή των μεταβλητών).
\item{Ανεξαρτησία των Σφαλμάτων}: Τα σφάλματα δεν είναι συσχετισμένα μεταξύ τους (δεν υπάρχει αυτοσυσχέτιση).
\item{Μη πολυσυγγραμμικότητα}: Οι ανεξάρτητες μεταβλητές δεν πρέπει να παρουσιάζουν ισχυρή συσχέτιση μεταξύ τους (αποφυγή πολυσυγγραμμικότητας), καθώς αυτό θα μπορούσε να οδηγήσει σε ασταθείς εκτιμήσεις συντελεστών.
\end{enumerate}
\item Είδη Γραμμικής Παλινδρόμησης: \begin{enumerate}
\item{Απλή Γραμμική Παλινδρόμηση}: Εξετάζει τη σχέση μεταξύ μιας εξαρτημένης μεταβλητής και μιας ανεξάρτητης μεταβλητής (π.χ., πρόβλεψη βάρους από το ύψος).
\item{Πολλαπλή Γραμμική Παλινδρόμηση}: Περιλαμβάνει πολλές ανεξάρτητες μεταβλητές και είναι κατάλληλη για πιο περίπλοκα προβλήματα όπου πολλοί παράγοντες επηρεάζουν το αποτέλεσμα. \end{enumerate}
\item Η γραμμική παλινδρόμηση είναι εύκολη στην ερμηνεία, γρήγορη στην εκπαίδευση και παρέχει ένα εύκολα κατανοητό μοντέλο. Επίσης, είναι πολύ χρήσιμη όταν επιδιώκεται η κατανόηση της σχέσης μεταξύ μεταβλητών.
\item Η απόδοση της γραμμικής παλινδρόμησης μπορεί να είναι χαμηλή σε περιπτώσεις όπου οι σχέσεις είναι μη γραμμικές ή οι υποθέσεις της παραβιάζονται. Επίσης, είναι ευαίσθητη στις ακραίες τιμές (outliers) και μπορεί να επηρεαστεί από την πολυσυγγραμμικότητα.
\end{enumerate}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/lr.jpeg} % Adjust the width as needed
    \caption{Linear Regression Model}
    \label{fig:your_image_label}
\end{figure}


Η γραμμική παλινδρόμηση (Linear Regression) αποτελεί ένα τρόπο μοντελοποίησης της σχέσης μεταξύ μιας μεταβλητής εξόδου και μιας ή περισσοτέρων εισόδων. Η μεταβλητή εξόδου ονομάζεται εξαρτημένη μεταβλητή, ενώ οι μεταβλητές εισόδου ονομάζονται ανεξάρτητες μεταβλητές. Στο μοντέλο της γραμμικής παλινδρόμησης γίνεται η υπόθεση ότι η σχέση αυτή είναι γραμμική, γεγονός που στην πραγματικότητα δε συμβαίνει συχνά.
Σημαντική προϋπόθεση για την παραγωγή του μοντέλου αυτού είναι η απουσία συσχέτισης μεταξύ των ανεξάρτητων μεταβλητών. Συχνά, όταν οι ανεξάρτητες μεταβλητές είναι περισσότερες από μια, το μοντέλο ονομάζεται \textit{πολλαπλή γραμμική παλινδρόμηση (multiple linear regression)}. Το μοντέλο έχει την εξής μορφή : \vspace{1cm}

Y = b_0 + b_1 X_{i1} + b_2 X_{i2} + \cdots + b_i X_{ip} + e_i, \quad \text{για κάθε δείγμα } i = 1, 2, \ldots, n \vspace{1cm}


Στην παραπάνω σχέση, Y είναι η εξαρτημένη μεταβλητή, X_{ij} είναι το i-οστό δείγμα της j ανεξάρτητης μεταβλητής X, όπου j=1,2,...,p. Ακόμη, b_i είναι οι παράμετροι του μοντέλου και e_i είναι η απόκλιση από της πραγματικές τιμές. Οι σταθερές παράμετροι b_i του μοντέλου, υπολογίζονται με τη μέθοδο των \textit{κανονικών ελάχιστων τετραγώνων}, το πρόβλημα έγκειται στην ελαχιστοποίηση της συνάρτησης απωλειών : \vspace{1cm}

L(X, y) = \sum_{i=1}^n (\hat{y}_i - y_i)^2 = \sum_{i=1}^n (b \cdot X_i - y_i)^2 \vspace{1cm}

\subsection{Λογιστική Παλινδρόμηση - Logistic Regression}

Η λογιστική παλινδρόμηση (\textit{Logistic Regression}) είναι ένας αλγόριθμος ταξινόμησης που χρησιμοποιείται για τη μοντελοποίηση της πιθανότητας εμφάνισης μιας δυαδικής εξαρτημένης μεταβλητής. Αντί να προβλέπει απευθείας τιμές, προβλέπει πιθανότητες, οι οποίες μετατρέπονται σε κατηγορίες μέσω ενός κατωφλίου.

\begin{enumerate}

\item Το μοντέλο βασίζεται στη λογιστική συνάρτηση (\textit{sigmoid function}), η οποία περιγράφεται ως:
\[
\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}
\]
όπου:
\[
z = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n
\]
και:
\begin{itemize}
    \item \( \hat{y} \): η πιθανότητα η παρατήρηση να ανήκει στην κατηγορία 1.
    \item \( z \): ο γραμμικός συνδυασμός των χαρακτηριστικών.
    \item \( x_1, x_2, \dots, x_n \): οι ανεξάρτητες μεταβλητές (χαρακτηριστικά).
    \item \( \beta_0, \beta_1, \dots, \beta_n \): οι συντελεστές του μοντέλου.
\end{itemize}

\item Η συνάρτηση κόστους που χρησιμοποιείται για την εκπαίδευση του μοντέλου είναι η αρνητική λογαριθμική πιθανοφάνεια (\textit{log-loss}):
\[
L(\beta) = - \frac{1}{m} \sum_{i=1}^{m} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
\]
όπου:
\begin{itemize}
    \item \( m \): ο αριθμός των δειγμάτων.
    \item \( y_i \): η πραγματική τιμή της εξαρτημένης μεταβλητής για το \( i \)-οστό δείγμα.
    \item \( \hat{y}_i \): η πιθανότητα που προβλέπει το μοντέλο για το \( i \)-οστό δείγμα.
\end{itemize}

\item Οι εκτιμήσεις των συντελεστών \( \beta \) γίνονται μέσω της μέγιστης πιθανοφάνειας (\textit{Maximum Likelihood Estimation - MLE}), ελαχιστοποιώντας τη συνάρτηση κόστους \( L(\beta) \).

\item Υποθέσεις της λογιστικής παλινδρόμησης:
\begin{itemize}
    \item Γραμμικότητα: Υπάρχει γραμμική σχέση μεταξύ των χαρακτηριστικών και του λογαρίθμου των πιθανοτήτων (\textit{log-odds}):
    \[
    \text{log-odds} = \log\left(\frac{P(y=1)}{P(y=0)}\right) = \beta_0 + \beta_1 x_1 + \dots + \beta_n x_n
    \]
    \item Ανεξαρτησία των παρατηρήσεων.
    \item Απουσία πολυσυγγραμμικότητας: Οι ανεξάρτητες μεταβλητές δεν πρέπει να είναι ισχυρά συσχετισμένες.
\end{itemize}

\item Το μοντέλο χρησιμοποιείται σε πλήθος εφαρμογών, όπως:
\begin{itemize}
    \item Πρόβλεψη δυαδικών γεγονότων, π.χ., αν ένας πελάτης θα αγοράσει ένα προϊόν.
    \item Αναγνώριση απάτης, π.χ., αν μια συναλλαγή είναι ύποπτη.
\end{itemize}

\end{enumerate}


\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/logreg.png} % Adjust the width as needed
    \caption{Logistic
     Regression Model}
    \label{fig:your_image_label}
\end{figure}


\section{Μετρικές Απόδοσης}

Οι μετρικές απόδοσης είναι εργαλεία που χρησιμοποιούνται για την αξιολόγηση της αποτελεσματικότητας και της ακρίβειας ενός αλγορίθμου ή μοντέλου μηχανικής μάθησης. Είναι ιδιαίτερα σημαντικές στην προσπάθειά μας να να ποσοτικοποιήσουμε το κατά πόσο καλά ένα μοντέλο προβλέπει ή ταξινομεί δεδομένα, επιτρέποντας έτσι τη σύγκριση διαφορετικών μοντέλων και φυσικά την επιλογή του καταλληλότερου.

\subsection{Accuracy}

Η ακρίβεια (accuracy) είναι ένας βασικός δείκτης απόδοσης των αλγορίθμων ταξινόμησης στη μηχανική μάθηση και εκφράζει το ποσοστό των σωστών προβλέψεων (θετικές και αρνητικές) σε σχέση με το συνολικό αριθμό των προβλέψεων. Ο υπολογισμός της ακρίβειας δίνεται από τη σχέση : 

\[
\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{Total Number of Samples}}
\]

όπου:

\begin{itemize}
\item TP (True Positives) είναι οι περιπτώσεις στις οποίες το μοντέλο προβλέπει σωστά μια θετική κατηγορία.
\item TN (True Negatives) είναι οι περιπτώσεις στις οποίες το μοντέλο προβλέπει σωστά μια αρνητική κατηγορία.
\end{itemize}


\subsection{F1 Score}

Το \textbf{F1 Score} είναι μια μετρική απόδοσης που χρησιμοποιείται για την αξιολόγηση μοντέλων ταξινόμησης, ειδικά όταν υπάρχει ανισορροπία μεταξύ των κατηγοριών ή όταν ενδιαφερόμαστε εξίσου για την \textit{Precision} και την \textit{Recall}. Ορίζεται ως ο αρμονικός μέσος του \textit{Precision} και του \textit{Recall}:

\[
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]

\subsection*{Precision και Recall}
Η έννοια του \textit{Precision} (Ευστοχία) και του \textit{Recall} (Ανάκληση) εξηγείται ως εξής:
\begin{itemize}
    \item \textbf{Precision:} Από όλες τις προβλέψεις που έγιναν ως θετικές, πόσες ήταν πράγματι σωστές:
    \[
    \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}
    \]
    \item \textbf{Recall:} Από όλες τις θετικές περιπτώσεις στο σύνολο δεδομένων, πόσες αναγνωρίστηκαν σωστά:
    \[
    \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}
    \]
\end{itemize}


Το \textbf{F1 Score} προσφέρει μία ενιαία τιμή που ισορροπεί το \textit{Precision} και το \textit{Recall}, κάτι που είναι κρίσιμο στις παρακάτω περιπτώσεις:
\begin{itemize}
    \item Όταν υπάρχει ανισορροπία στις κλάσεις (π.χ. μία κλάση εμφανίζεται πολύ πιο συχνά από την άλλη).
    \item Όταν το \textit{Accuracy} δίνει παραπλανητική εικόνα λόγω ασύμμετρων ψευδών προβλέψεων (\textit{False Positives} και \textit{False Negatives}).
\end{itemize}

Ένα υψηλό \textbf{F1 Score} υποδηλώνει ότι το μοντέλο έχει καλή ισορροπία μεταξύ \textit{Precision} και \textit{Recall}.

\subsection{Mathews Correlation Coefficient - MCC}


Το \textbf{Matthews Correlation Coefficient (MCC)} είναι μία μετρική που αξιολογεί την ποιότητα ενός ταξινομητή, ειδικά σε προβλήματα με ανισορροπία στις κλάσεις. Υπολογίζει τη συσχέτιση μεταξύ των πραγματικών τιμών και των προβλέψεων, λαμβάνοντας υπόψη όλους τους τύπους σφαλμάτων: \textit{True Positives (TP)}, \textit{True Negatives (TN)}, \textit{False Positives (FP)}, και \textit{False Negatives (FN)}. Ο μαθηματικός του ορισμός είναι:

\[
MCC = \frac{(TP \cdot TN) - (FP \cdot FN)}{\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}
\]

\begin{itemize}
    \item \textbf{Τιμές:}
    Το MCC κυμαίνεται από \(-1\) έως \(+1\):
    \begin{itemize}
        \item \(+1:\) Ιδανική ταξινόμηση (όλες οι προβλέψεις σωστές).
        \item \(0:\) Τυχαία πρόβλεψη (καμία συσχέτιση).
        \item \(-1:\) Απόλυτα λανθασμένη ταξινόμηση (αντιστροφή όλων των προβλέψεων).
    \end{itemize}
    
\item Το MCC είναι κατάλληλο για ανισόρροπα σύνολα δεδομένων, καθώς ενσωματώνει όλες τις κατηγορίες λαθών στη σχέση του.

\item  Σε περιπτώσεις ανισορροπίας, το MCC θεωρείται πιο αξιόπιστο από το \textit{F1 Score}, καθώς δίνει μια συνολική εικόνα για την απόδοση του ταξινομητή.
\end{itemize}

Το MCC είναι κατάλληλο:
\begin{itemize}
    \item Για προβλήματα δυαδικής ή πολυκατηγορικής ταξινόμησης.
    \item Όταν υπάρχει σημαντική ανισορροπία στις κλάσεις.
    \item Όταν απαιτείται μια γενική μετρική που να ενσωματώνει όλες τις διαστάσεις των προβλέψεων (σωστά και λάθη).
\end{itemize}

Το \textbf{MCC} είναι μία από τις πιο αξιόπιστες μετρικές για την αξιολόγηση ταξινομητών, ιδιαίτερα σε περιπτώσεις με ανισορροπία στις κλάσεις. Παρέχει μια συνολική εικόνα της απόδοσης του μοντέλου, λαμβάνοντας υπόψη τόσο τις σωστές όσο και τις λανθασμένες προβλέψεις.


\subsection{Confusion Matrix}

Η \textbf{Confusion Matrix} είναι ένας πίνακας που χρησιμοποιείται για την απεικόνιση της απόδοσης ενός ταξινομητή σε προβλήματα κατηγοριοποίησης. Απεικονίζει τον αριθμό των σωστών και λανθασμένων προβλέψεων που έκανε το μοντέλο, κατηγοριοποιημένες ανά κλάση. Ο πίνακας έχει την εξής γενική μορφή για δυαδική ταξινόμηση:

\[
\begin{bmatrix}
\text{True Positives (TP)} & \text{False Positives (FP)} \\
\text{False Negatives (FN)} & \text{True Negatives (TN)}
\end{bmatrix}
\]

\begin{itemize}
    \item \textbf{True Positives (TP):} Οι περιπτώσεις όπου το μοντέλο προέβλεψε σωστά την θετική κλάση.
    \item \textbf{False Positives (FP):} Οι περιπτώσεις όπου το μοντέλο προέβλεψε λανθασμένα τη θετική κλάση ενώ η πραγματική ήταν αρνητική (\textit{Type I Error}).
    \item \textbf{False Negatives (FN):} Οι περιπτώσεις όπου το μοντέλο προέβλεψε λανθασμένα την αρνητική κλάση ενώ η πραγματική ήταν θετική (\textit{Type II Error}).
    \item \textbf{True Negatives (TN):} Οι περιπτώσεις όπου το μοντέλο προέβλεψε σωστά την αρνητική κλάση.
\end{itemize}

Η Confusion Matrix είναι χρήσιμη για τον υπολογισμό πολλών μετρικών απόδοσης, όπως:
\begin{itemize}
    \item \textbf{Accuracy:}
    \[
    \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
    \]
    \item \textbf{Precision:}
    \[
    \text{Precision} = \frac{TP}{TP + FP}
    \]
    \item \textbf{Recall (ή Sensitivity):}
    \[
    \text{Recall} = \frac{TP}{TP + FN}
    \]
    \item \textbf{F1 Score:}
    \[
    F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
    \]
\end{itemize}

Η \textbf{Confusion Matrix} προσφέρει μια ολοκληρωμένη εικόνα της απόδοσης ενός ταξινομητή, καθώς περιλαμβάνει όλες τις κατηγορίες λαθών (FP, FN) και σωστών προβλέψεων (TP, TN). Είναι ένα κρίσιμο εργαλείο για την ανάλυση της συμπεριφοράς ενός μοντέλου ταξινόμησης, ειδικά όταν χρησιμοποιείται μαζί με άλλες μετρικές απόδοσης.



\chapter{Παρουσίαση Συνόλου Δεδομένων}

\sloppy
Οι δικαστικές αποφάσεις που χρησιμοποιήθηκαν στην παρούσα εργασία συλλέχθηκαν από το Εφετείο Πειραιώς \href{https://www.efeteio-peir.gr/?page\_id=4017}{(https://www.efeteio-peir.gr/?page\_id=4017)} και από τον Άρειο Πάγο \href{https://www.areiospagos.gr/nomologia/apofaseis.asp}{(https://www.areiospagos.gr/nomologia/apofaseis.asp)}. 
Πρόκειται για αποφάσεις που ελήφθησαν κατά τα έτη 2009, 2018, 2021 και 2022 από τα συγκεκριμένα δικαστήρια και καλύπτουν διάφορους τομείς του δικαίου. Τόσο η προεπεξεργασία των δεδομένων αλλά και η επισημείωσή τους ήταν απαραίτητες διαδικασίες προκειμένου να δημιουργηθεί η τελική μορφή του συνόλου δεδομένων προς μελέτη. Οι λεπτομέρειες των διαδικασιών αυτών θα αναλυθούν παρακάτω.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/dataset.png} % Adjust the width as needed
    \caption{Αποφάσεις Δικαστηρίων}
    \label{fig:your_image_label}
\end{figure}

Η παραπάνω γραφική απεικόνιση παρουσιάζει τον αριθμό αποφάσεων στα δεδομένα που χρησιμοποιούνται για ανάλυση, τόσο στο αρχικό όσο και στο τελικό σύνολο. Συγκεκριμένα:

\begin{itemize}
\item Οι μπλε γραμμές αντιστοιχούν στον αρχικό αριθμό αποφάσεων που υπήρχαν στο dataset πριν τη διαδικασία εξισορρόπησης. 
\item Οι πορτοκαλί γραμμές δείχνουν τον αριθμό αποφάσεων μετά τη διαδικασία εξισορρόπησης, η οποία εφαρμόστηκε για τη δημιουργία ενός balanced dataset, γεγονός που βελτιώνει την αξιοπιστία των αποτελεσμάτων κατά την εφαρμογή μοντέλων μηχανικής μάθησης.
\end{itemize}


\section{Προεπεξεργασία Δεδομένων}

Ο πρωταρχικός στόχος της προεπεξεργασίας των δεδομένων είναι να προετοιμάσουμε το κείμενο, αφαιρώντας περιττούς χαρακτήρες, αριθμούς, και αγγλικούς χαρακτήρες, έτσι ώστε να διευκολύνουμε την διαδικασία ανάλυσης και την επεξεργασία τους. Οι συγκεκριμένες ενέργειες είναι απαραίτητες με σκοπό να φέρουμε τις δικαστικές αποφάσεις σε μορφή κατάλληλη για τα μοντέλα που θα εξετάσουμε στην συνέχεια. Η διαδικασία προεπεξεργασίας των κειμένων είναι ένα κρίσιμο βήμα στην προετοιμασία των δεδομένων για τη χρήση τους σε αλγορίθμους μηχανικής μάθησης. Για την προεπεξεργασία των δικαστικών αποφάσεων, ακολουθήσαμε μια σειρά από βήματα που στοχεύουν στην αργότερα αποτελεσματική ανάλυση των κειμένων από τα μοντέλα.

\begin{enumerate}
\item \textit{Μετατροπή σε πεζά :} Όλα τα γράμματα μετατράπηκαν σε πεζά για να εξασφαλιστεί η συνέπεια και να αποφεύγεται η διάκριση μεταξύ κεφαλαίων και πεζών χαρακτήρων, που δεν θα πρόσθεταν κάποια αξία στην ανάλυση.
\item \textit{Αφαίρεση τονισμού :} Οι τόνοι αφαιρέθηκαν από τις λέξεις, διευκολύνοντας την ταύτιση όρων με και χωρίς τόνο, όπως «δικαστής» και «δικαστης», τα οποία θα αντιμετωπίζονταν ως διαφορετικές λέξεις από τον αλγόριθμο.
\item \textit{Αφαίρεση σημείων στίξης :} Τα σημεία στίξης αφαιρέθηκαν, καθώς δεν προσφέρουν πληροφορίες χρήσιμες για την εκπαίδευση των μοντέλων πρόβλεψης. Αυτό περιλαμβάνει όλα τα σημεία στίξης, όπως κόμματα, τελείες, ερωτηματικά κ.λπ.
\item \textit{Αφαίρεση αριθμών :} Οι αριθμοί αφαιρέθηκαν από τα κείμενα, καθώς σε πολλές περιπτώσεις δεν παρέχουν ουσιαστικές πληροφορίες για την ανάλυση, ιδιαίτερα όταν δεν συνδέονται με κρίσιμες πληροφορίες για το νόημα των αποφάσεων.
\item \textit{Αφαίρεση αγγλικών χαρακτήρων :} Επειδή οι δικαστικές αποφάσεις είναι στα ελληνικά, οποιοσδήποτε αγγλικός χαρακτήρας αφαιρέθηκε από τα δεδομένα.
\item \textit{Αφαίρεση ειδικών χαρακτήρων :} Αφαιρέθηκαν ειδικοί χαρακτήρες όπως η κάτω παύλα, που δεν προσθέτουν νόημα στο κείμενο και μπορεί να προκαλέσουν προβλήματα στη διαδικασία ανάλυσης.
\item \textit{Αφαίρεση λέξεων-κλειδιά :} Αφαιρέθηκαν λέξεις-κλειδιά, δηλαδή συχνές λέξεις οι οποίες δεν φέρουν σημαντική σημασιολογική πληροφορία, με χρήση της λίστας που παρέχεται από το NLTK \href{https://github.com/hb20007/hands-on-nltk-tutorial/blob/main/7-1-NLTK-with-the-Greek-Script.ipynb}{(https://github.com/hb20007/hands-on-nltk-tutorial/blob/main/7-1-NLTK-with-the-Greek-Script.ipynb)}.

\section{Διαδικασία Επισημείωσης}

Μετά την ολοκλήρωση της προεπεξεργασίας των κειμένων των δικαστικών αποφάσεων, προχωρήσαμε στην φάση της επισημείωσης των δεδομένων, προκειμένου να κατηγοριοποιήσουμεε της αποφάσεις δυαδικά, δηλαδή ως αποδοχή ή απόρριψη. Η επισημείωση είναι ένα κρίσιμο βήμα στη διαδικασία ανάλυσης δεδομένων, ιδιαίτερα όταν χρησιμοποιούνται τεχνικές μηχανικής μάθησης. Η ακρίβεια της επισημείωσης ενός συνόλου δεδομένων, επηρεάζει άμεσα την απόδοση των μοντέλων πρόβλεψης που θα εκπαιδευτούν πάνω σε αυτά τα δεδομένα. Στην περίπτωση των δικαστικών αποφάσεων, η σωστή ετικετοποίησης (\textit{labeling}) των δεδομένων είναι καθοριστική για την ανάπτυξη αξιόπιστων αλγορίθμων που μπορούν να βοηθήσουν στη βελτίωση της δικαστικής διαδικασίας. 
Η επισημείωση βασίστηκε στην ύπαρξη συγκεκριμένων  (\textit{regular expressions}) που χρησιμοποιούνται από τα δύο δικαστήρια, οι οποίες υποδηλώνουν την αποδοχή της αίτησης ή της έφεσης. Η διαδικασία που ακολουθήσαμε αναλύεται παρακάτω :

\begin{enumerate}
\item \textit{Ανάκτηση κειμένου :} Τα δεδομένα που χρησιμοποιήθηκαν προήλθαν από δικαστικές αποφάσεις αποθηκευμένες σε αρχεία PDF και HTML. Για την εξαγωγή του κειμένου από τα αρχεία HTML, χρησιμοποιήθηκε το εργαλείο BeautifulSoup, το οποίο επιτρέπει την ανάκτηση του πλήρους περιεχομένου των αποφάσεων. Αντίστοιχα, για τα αρχεία PDF και CSV, χρησιμοποιήθηκε η Python βιλβιοθήκη pandas προκειμένουν να γίνει η εξαγωγή του κειμένου αγνοώντας tags κι άλλες δομικές πληροφορίες που περιέχονται στα αρχεία. Αυτή η διαδικασία εξασφάλισε ότι το κείμενο εξάγεται με συνέπεια και ακρίβεια, ανεξάρτητα από την πηγή του.
\item \textit{Αναζήτηση στόχων - target words :} Προκειμένου να γίνει ορθή κατηγοριοποίηση των αποφάσεων που εξετάζουμε, σε προγραμματιστικό επίπεδο, καθορίσαμε μια λίστα από (\textit{regular expressions}), η οποία χρησιμοπείται συνήθως σε αποφάσεις που καταλήγουν σε αποδοχή. Οι εκφράσεις αυτές, π.χ. «δέχεται τυπικά και κατ’ ουσίαν» ή «δέχεται τυπικά και ουσιαστικά», επιλέχθηκαν με βάση την ανάλυση της γλώσσας που χρησιμοποιείται στα δικαστικά κείμενα που εξετάζουμε και αντιστοιχούν σε περιπτώσεις όπου το δικαστήριο κάνει αποδεκτή την αίτηση ή την έφεση. Οι αποφάσεις που περιείχαν αυτές τις φράσεις επισημάνθηκαν ως αποδοχή (με την ένδειξη 0), ενώ οι υπόλοιπες επισημάνθηκαν ως απορρίψη (με την ένδειξη 1).
\item \textit{Δημιουργία συνόλου δεδομένων :} Μετά την αναζήτηση των λέξεων-στόχων, οι αποφάσεις επισημάνθηκαν κατάλληλα, και το αποτέλεσμα αποθηκεύτηκε σε ένα δομημένο σύνολο δεδομένων (CSV αρχείο), το οποίο περιέχει για κάθε απόφαση το όνομα του αρχείου και την αντίστοιχη κατηγορία στην οποία ανήκει.


Με το πέρας της διαδικασίας της επισημείωσης, το σύνολο των δικαστικών αποφάσεων είναι πλέον έτοιμο για την επόμενη φάση της μελέτης μας, όπου θα εφαρμοστούν τεχνικές μηχανικής μάθησης για την εξαγωγή προβλέψεων σχετικά με την έκβαση μελλοντικών υποθέσεων.

 
\chapter{Μέθοδοι Πρόβλεψης Δικαστικών Αποφάσεων}


\section{Προετοιμασία Κειμένων}

Προκειμένου να εξετάσουμε την αποτελεσματικότητα των διαφόρων ταξινομητών στο σύνολο των αποφάσεων που έχουμε στη διάθεσή μας ήταν απαραίτητο να αναπαραστίσουμε τα κείμενα των αποφάσεων σε αριθμητική μορφή.

Το TF-IDF (\textit{Term Frequency-Inverse Document Frequency}) είναι μία από τις πιο διαδεδομένες και αποτελεσματικές τεχνικές για την αναπαράσταση αυτή, στην Επεξεργασία Φυσικής Γλώσσας (\textit{NLP}). Το TF-IDF είναι ουσιαστικά μια αριθμητική στατιστική που προορίζεται να αντικατοπτρίζει τη σημασία μιας λέξης για ένα έγγραφο σε μια συλλογή ή ένα σώμα κειμένων. Πιο συγκεκριμένα, η τεχνική που εφαρμόσαμε στις αποφάσεις συνδυάζει δύο βασικές έννοιες: τη συχνότητα εμφάνισης μιας λέξης σε ένα έγγραφο (Term Frequency) και τη σπανιότητα αυτής της λέξης στο σύνολο των εγγράφων (Inverse Document Frequency).

Αναλυτικότερα, η συνάρτηση TF μετρά πόσες φορές μια λέξη εμφανίζεται σε ένα έγγραφο σε σχέση με το συνολικό αριθμό λέξεων, ενώ η συνάρτηση IDF μειώνει τη βαρύτητα των όρων που εμφανίζονται σε πολλά έγγραφα, καθώς αυτοί δεν είναι τόσο διακριτικοί. Ο πολλαπλασιασμός των δύο αυτών μεγεθών οδηγεί σε μια μετρική που αναδεικνύει τους πιο "σημαντικούς" όρους για κάθε έγγραφο. Το TF-IDF χρησιμοποιείται ευρέως σε συστήματα ανάκτησης πληροφορίας και ταξινομήσεις κειμένων.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/tfidf.png} % Adjust the width as needed
    \caption{Αναπαράσταση TF-IDF}
    \label{fig:your_image_label}
\end{figure}


Στην παρούσα διπλωματική εργασία χρησιμοποιείται το αντικείμενο Tf-idfVectorizer(), το οποίο δέχεται ως είσοδο κείμενο και εξάγει διανύσματα (vectors) σε ένα μοντέλο διανυσματικού χώρου. Το αντικείμενο αυτό ανάλογα με τα ορίσματα που δέχεται διαχειρίζεται και διαφορετικά τα δεδομένα. 


Οι μεταβλητές maxdf και mindf, που αποτελούν επίσης παραμέτρους του Tf-idfVectorizer(), παίζουν εξίσου σημαντικό ρόλο και βοηθούν στη μείωση των διαστάσεων κάθε μοντέλου, καθώς μπορούν ανάλογα με τις τιμές που θα λάβουν να περιορίσουν το εύρος του λεξιλογίου που δημιουργείται.. Όσον αφορά στο maxdf, με την τιμή 0,5 δηλώνεται ότι πρόκειται να αγνοηθούν όλοι οι όροι που εμφανίζονται σε πάνω από το 50 τοις εκατό των δεδομένων, ενώ σχετικά με την τιμή του mindf δηλώνεται ότι δεν θα ληφθούν υπόψη οι όροι που υπάρχουν σε λιγότερο από 10 έγγραφα.



\section{Ρύθμιση Υπερπαραμέτρων των Μοντέλων}

Η σωστή λειτουργία πολλών από τους αλγορίθμους μηχανικής μάθησης, βασίζεται στη σωστή ρύθμιση των παραμέτρων τους. Οι υπερπαράμετροι (hyperparameters) συνιστούν τις μεταβλητές που χαρακτηρίζουν τη διαδικασία εκπαίδευσης του εκάστοτε μοντέλου. Οι τιμές τους πρέπει να ρυθμιστούν από τον προγραμματιστή προτού αρχίσει η διαδικασία εκπαίδευσης, εν αντιθέσει με τις απλές παραμέτρους του μοντέλου, η τιμή των οποίων υπολογίζεται αυτομάτως -κατά την εκπαίδευση- από το ίδιο το μοντέλο. Ως εκ τούτου, γίνεται κατανοητή η σημασία της επιλογής των κατάλληλων υπερπαραμέτρων για την αποδοτική λειτουργία κάθε μοντέλου. Ωστόσο, δεν υπάρχουν σαφείς και ακριβείς κανόνες που να προσδιορίζουν τον τρόπο με τον οποίο πρέπει να γίνει αυτή η επιλογή. Οι αλγόριθμοι που επιτελούν την ρύθμιση των υπερπαραμέτρων λειτουργούν σύμφωνα με τη μέθοδο δοκιμής-σφάλματος, προβαίνοντας σε συνεχόμενες επιλογές τιμών, εως ότου φτάσουν στις βέλτιστες τιμές. Επομένως, σημαντικό βήμα αποτελεί η επιλογή των τιμών εκείνων που θα υποβληθούν σε αυτή τη διαδικασία βελτιστοποίησης.

Υπάρχουν ελάχιστες καθολικές συμβουλές σχετικά με την επιλογή των τιμών αυτών, ενώ η τελική επιτυχία της
διαδικασίας εξαρτάται σε μεγάλο βαθμό από την εμπειρία του προγραμματιστή. Η επιλογή τους πρέπει να γίνεται με σύνεση, καθώς κάθε παράμετρος που επιλέγεται να ρυθμιστεί μπορεί να αυξήσει εκθετικά τον απαιτούμενο αριθμό των δοκιμών. Αφού επιλεχθούν οι παράμετροι προς ρύθμιση, εφαρμόζονται αλγόριθμοι, οι οποίοι προελαύνουν το χώρο αναζήτησης που 85 δημιουργείται, το μέγεθος του οποίου εξαρτάται από το πλήθος και το εύρος των υπερπαραμέτρων που έχουν επιλεχθεί να ρυθμιστούν. Οι δύο πλέον χρησιμοποιούμενοι από τους αλγορίθμους αυτούς είναι οι :
\vspace{0.5cm}



\begin{enumerate}
\item \textbf{Αναζήτηση Πλέγματος} (\textit{Grid Search}). Η αναζήτηση πλέγματος αποτελεί τον απλούστερο αλγόριθμο βελτιστοποίησης υπερπαραμέτρων. Ο αλγόριθμος αυτός εκτελεί μια εξαντλητική αναζήτηση στο προκαθορισμένο χώρο αναζήτησης που δημιουργείται. Ο χώρος αναζήτησης μπορεί να καταλήξει να αποτελεί ένα υπερεπίπεδο δεκάδων διαστάσεων, ανάλογα με το πλήθος των προς ρύθμιση παραμέτρων. 
\item \textbf{Τυχαία Αναζήτηση} (\textit{Randomized Search}). Στην τυχαία αναζήτηση, ο χώρος αναζήτησης διασχίζεται τυχαία έως ότου ικανοποιηθεί κάποιο κριτήριο τερματισμού, όπως ο αριθμός των επαναλήψεων. Ο αλγόριθμος αυτός δεν εγγυάται την εύρεση της βέλτιστης λύσης, αλλά λειτουργεί ικανοποιητικά σε προβλήματα που το πλήθος των υπερπαραμέτρων είναι μικρό, ενώ επιλέγεται επίσης, όταν δεν είναι διαθέσιμη μεγάλη υπολογιστική ισχύς.
\end{enumerate}
\vspace{0.5cm}




Ένας κύριος λόγος μη αποδοτικότητας ενός μοντέλου μηχανικής μάθησης είναι η υπερπροσαρμογή (\textit{overfitting}). Ο συγκεκριμένος όρος χρησιμοποιείται στην επιβλεπόμενη μάθηση για να δηλώσει την κατάσταση κατά την οποία ένα μοντέλο έχει εκπαιδευτεί και εξειδικευτεί στο σύνολο εκπαίδευσης του προβλήματος που εξετάζεται, με αποτέλεσμα να παρουσιάζει χαμηλή ακρίβεια στην πρόβλεψη του συνόλου δοκιμής. \vspace{0.5cm}

Προκειμένου να αντιμετωπιστεί το παραπάνω πρόβλημα, χρησιμοποιήθηκε η τεχνική \textit{Cross-Validation}(CV), η οποία αποτελεί την πλέον ενδεικνυόμενη λύση. Με την τεχνική αυτή, δεν απαιτείται πλέον η δέσμευση ενός μέρους του συνόλου εκπαίδευσης σα σύνολο αξιολόγησης, με αποτέλεσμα τα μοντέλα να εκπαιδεύονταιμε το μέγιστο δυνατό αριθμό δειγμάτων. Ωστόσο, το σύνολο δοκιμής εξακολουθεί να υπάρχει για την τελική αξιολόγηση των μοντέλων. Η βασική πρακτική της εν λόγω τεχνικής ονομάζεται \textit{k-fold Cross-Validation}. Πιο συγκεκριμένα, επιλέγεται ένας σταθερός αριθμός από \textit{folds (πτυχές)}, δηλαδή συνεχόμενες διαιρέσεις των δεδομένων. Τα δεδομένα διαχωρίζονται σε \textit{k} προσεγγιστικά ίσα folds και κάθε ένα στη συνέχεια θα χρησιμοποιηθεί επαναληπτικά για την αξιολόγηση, ενώ τα υπόλοιπα για την εκπαίδευση των μοντέλων. Τα k−1 folds χρησιμοποιούνται ως σύνολο εκπαίδευσης, ενώ το 1 fold λειτουργεί ως σύνολο αξιολόγησης. Η διαδικασία αυτή επαναλαμβάνεται συνολικά  k φορές, διασφαλίζοντας ότι κάθε δείγμα του συνόλου δεδομένων αξιολογείται μία φορά και συμμετέχει k−1 φορές στο σύνολο εκπαίδευσης. Τυπικές τιμές του k είναι της τάξεως του 5 έως 10. Η συνολική αξιολόγηση του μοντέλου προκύπτει από τη μέση τιμή των επιμέρους αξιολογήσεων που προέκυψαν κατά τις k επαναλήψεις. Η διαδικασία αυτή, μπορεί να επαναληφθεί για κάθε τιμή των υπερπαραμέτρων που δοκιμάζονται, ώστε να επιλεχθούν τελικά οι βέλτιστες. Είναι σαφές ότι η πρακτική αυτή έχει μεγάλο υπολογιστικό κόστος, καθώς απαιτούνται πολλοί κύκλοι εκπαίδευσης του μοντέλου. Ωστόσο, η σημασία της έγκειται στο γεγονός ότι δε δεσμεύει μεγάλο μέρος των διαθέσιμων διεγμάτων προς αξιολόγηση, γεγονός θεμελιώδους σημασίας όταν ο αριθμός των δειγμάτων είναι περιορισμένος. \vspace{0.5cm}

Στην παρούσα εργασία, τόσο η μέθοδος Grid Search όσο και η Randomized Search χρησιμοποιήθηκαν μέσω των σχετικών συναρτήσεων της βιβλιοθήκης scikit-learn, για την βέλτιστη ρύθμιση των υπερπαραμέτρων των μοντέλων. Η δεύτερη μέθοδος χρησιμοποιήθηκε, λόγω του απαγορευτικά υψηλού υπολογιστικού χρόνου που απαιτούταν, σε περιπτώσεις μοντέλων με μεγάλο αριθμό υπερπαραμέτρων και πολλές υπό δοκιμή τιμές. Οι δύο αυτοί αλγόριθμοι, δέχονται σαν ορίσματα το μοντέλο πρόβλεψης, τα σύνολα τιμών των υπερπαραμέτρων που θα δοκιμαστούν, την τεχνική Cross-Validation που θα εφαρμοστεί και τον τρόπο με τον οποίο θα γίνει η αξιολόγηση (scoring) του μοντέλου. Στη συνέχεια, για κάθε δυνατό συνδυασμό των υπερπαραμέτρων του ορίσματος, εκτελείται η σχετική τεχνική Cross-Validation και προκύπτει η αξιολόγηση του εκάστοτε μοντέλου. Τέλος, ο αλγόριθμος επιλέγει το μοντέλο με εκείνες τις υπερπαραμέτρους που έδωσαν την υψηλότερη απόδοση στο σύνολο αξιολόγησης της τεχνικής Cross-Validation.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{~/Desktop/thesis_images/gridrand.png} % Adjust the width as needed
    \caption{Grid vs Random Search Model}
    \label{fig:your_image_label}
\end{figure}

\section{Εκπαίδευση Μοντέλων}

\subsection{Random Forest}

Στην υλοποίηση του μοντέλου Random Forest της παρούσας διπλωματικής εργασίας, τα δεδομένα χωρίστηκαν  σε χαρακτηριστικά (\textit{features}) και ετικέτες (\texit{labels}). Στη συνέχεια, πραγματοποιήθηκε διαχωρισμός (\textit{split}) του συνόλου δεδομένων σε ένα σύνολο εκπαίδευσης (67\% του αρχικού συνόλου δεδομένων) και σε ένα σύνολο δοκιμής (33\%) με το train\_test\_split. Η παράμετρος stratify = y εξασφαλίζει ότι η κατανομή των κατηγοριών στο εκπαιδευτικό και στο δοκιμαστικό σύνολο είναι ισόρροπη ως προς την αρχική κατανομή των κατηγοριών. 

Το Random Forest αρχικοποιείται ως μοντέλο, και καθορίζεται ένα πλέγμα υπερπαραμέτρων (param\_grid), που περιλαμβάνει παραμέτρους όπως ο αριθμός των δέντρων (n\_estimators), το μέγιστο βάθος δέντρων (max\_depth), ο ελάχιστος αριθμός παραδειγμάτων για διαχωρισμό ή φύλλα (min\_samples\_split και min\_samples\_leaf), και η μέθοδος επιλογής χαρακτηριστικών για διαχωρισμό (max\_features).

%Με τη χρήση του GridSearchCV, το μοντέλο εκπαιδεύεται με διαφορετικούς συνδυασμούς παραμέτρων, χρησιμοποιώντας 5-πτυχη διασταυρούμενη επικύρωση και το scoring='f1' για να βελτιστοποιήσει το F1 Score, το οποίο είναι κρίσιμο για προβλήματα με ανισόρροπα δεδομένα. Το GridSearchCV επιλέγει τον καλύτερο συνδυασμό παραμέτρων, και το καλύτερο μοντέλο εφαρμόζεται στο σύνολο δοκιμών. Η απόδοση αξιολογείται μέσω μετρικών όπως η ακρίβεια, το F1 Score, και ο συντελεστής συσχέτισης Matthews (MCC). Επιπλέον, η οπτικοποίηση του πίνακα σύγχυσης (\textit{confusion matrix}),  προσφέρει μια καθαρή εικόνα των σωστών και λανθασμένων προβλέψεων, ενώ το n\_jobs=-1 διασφαλίζει την αποδοτική χρήση όλων των διαθέσιμων υπολογιστικών πόρων. Συνολικά, αυτή η διαδικασία συνδυάζει την αυτοματοποιημένη βελτιστοποίηση, την ενδελεχή αξιολόγηση, και την ισχυρή μοντελοποίηση για την επίτευξη βέλτιστων προβλέψεων.

\subsection{SVM}

Αντίστοιχα, για το μοντέλο SVM (\textit{Support Vector Machine}), τα δεδομένα χωρίστηκαν σε χαρακτηριστικά και ετικέτες και στη συνέχεια κατανεμήθηκαν σε σύνολα εκπαίδευσης και δοκιμών, με τη μέθοδο train\_test\_split, διατηρώντας τις αναλογίες των κατηγοριών με το stratify, ενώ η επαναληψιμότητα εξασφαλίστηκε μέσω του random\_state. Το SVM μοντέλο αρχικοποιείται και συνοδεύεται από ένα πλέγμα παραμέτρων (\texit{param\_grid}) που περιλαμβάνει διαφορετικές τιμές για τον παράγοντα κανονικοποίησης C, τον συντελεστή του πυρήνα gamma, και τους τύπους πυρήνα (linear και rbf), έτσι ώστε να εξερευνηθούν ποικίλες πιθανές ρυθμίσεις. Με τη βοήθεια του GridSearchCV και την πεντάπτυχη (\texit{5-fold}) διασταυρούμενη επικύρωση, το μοντέλο βελτιστοποιείται, προκειμένου να μεγιστοποιήσει το F1 Score. Πιο συγκεκριμένα, στη διαδικασία επιλογής των καλύτερων υπερπαραμέτρων του SVM, ο αλγόριθμος GridSearchCV αξιολογεί τις διάφορες συνδυαστικές ρυθμίσεις παραμέτρων (C, gamma, και kernel) με βάση το F1 Score. Παράλληλα, χρησιμοποιείται το n\_jobs=-1 για την αξιοποίηση όλων των διαθέσιμων πόρων επεξεργασίας. 

%Αφού βρεθούν οι καλύτερες παράμετροι, το βελτιστοποιημένο μοντέλο εφαρμόζεται στο σύνολο δοκιμών, και η απόδοσή του αξιολογείται μέσω της ακρίβειας (\texit{accuracy}), του F1 Score, και του πίνακα σύγχυσης (\textit{confusion matrix}), ο οποίος οπτικοποιείται με τη βοήθεια της βιβλιοθήκης seaborn. H συγκεκριμένη προσέγγιση εξασφαλίζει μια ολοκληρωμένη αξιολόγηση της απόδοσης του μοντέλου και βελτιστοποιεί τις προβλέψεις με βάση τα συγκεκριμένα δεδομένα.

\subsection{Logistic Regression}

Για την ανάπτυξη του μοντέλου λογιστικής παλινδρόμησης (\textit{Logistic Regression}), αρχικά τα δεδομένα διαχωρίστηκαν σε χαρακτηριστικά X και ετικέτες y, ενώ στη συνέχεια πραγματοποιήθηκε κατανομή τους σε σύνολα εκπαίδευσης και δοκιμών, χρησιμοποιώντας τη μέθοδο \textit{train\_test\_split}. Η διαδικασία αυτή διασφάλισε τη διατήρηση της αναλογίας των κατηγοριών μέσω της παραμέτρου \textit{stratify}, ενώ για την επαναληψιμότητα χρησιμοποιήθηκε σταθερό \textit{random\_state}. Ακολούθως, εφαρμόστηκε κανονικοποίηση των δεδομένων χαρακτηριστικών με τη χρήση της κλάσης \textit{StandardScaler}, ώστε να διασφαλιστεί ότι όλες οι μεταβλητές βρίσκονται στην ίδια κλίμακα. Στη συνέχεια, το μοντέλο λογιστικής παλινδρόμησης αρχικοποιήθηκε με μέγιστο αριθμό επαναλήψεων (\textit{max\_iter}) ορισμένο στις 2000 και εφαρμόστηκε πλέγμα παραμέτρων (\textit{param\_grid}), το οποίο περιελάμβανε διάφορες τιμές για την παράμετρο κανονικοποίησης C (αντίστροφο της ισχύος της ποινής), διαφορετικά είδη κανονικοποίησης (\textit{penalty}) και επιλογές αλγορίθμων (\textit{solver}).

%Η επιλογή των βέλτιστων υπερπαραμέτρων πραγματοποιήθηκε με τη χρήση του \textit{GridSearchCV} και πεντάπτυχης διασταυρούμενης επικύρωσης (\textit{5-fold cross-validation}). Κατά την εκπαίδευση, αξιολογήθηκε η απόδοση κάθε συνδυασμού παραμέτρων με βάση τον \textit{F1 Score}, ενώ χρησιμοποιήθηκε \textit{n\_jobs=-1} για την αξιοποίηση όλων των διαθέσιμων πόρων επεξεργασίας. Μετά την ολοκλήρωση της διαδικασίας, επιλέχθηκε το μοντέλο με τις καλύτερες υπερπαραμέτρους και έγινε πρόβλεψη των τιμών του συνόλου δοκιμών. Για την αξιολόγηση του μοντέλου, υπολογίστηκε η ακρίβεια (\textit{Αccuracy}) και ο \textit{F1 Score}, ενώ παράχθηκε και οπτικοποιήθηκε ο πίνακας σύγχυσης (\textit{confusion matrix}) με τη βοήθεια της βιβλιοθήκης \textit{seaborn}. Αυτή η προσέγγιση διασφάλισε την εύρεση βέλτιστων παραμέτρων για τη λογιστική παλινδρόμηση και την ολοκληρωμένη αξιολόγηση της απόδοσης του μοντέλου στο συγκεκριμένο σύνολο δεδομένων.

\subsection{Decision Trees}

Αντίστοιχα, για το μοντέλο Δέντρων 
Απόφασης (\textit{Decision Trees}), τα δεδομένα χωρίστηκαν σε χαρακτηριστικά και ετικέτες και στη συνέχεια κατανεμήθηκαν σε σύνολα εκπαίδευσης και δοκιμών, με τη μέθοδο \textit{train\_test\_split}, διατηρώντας τις αναλογίες των κατηγοριών με τη χρήση του \textit{stratify}, ενώ η επαναληψιμότητα εξασφαλίστηκε μέσω του \textit{random\_state}. Το μοντέλο αρχικοποιείται μέσω του \textit{DecisionTreeClassifier} και εκπαιδεύεται στο σύνολο εκπαίδευσης χρησιμοποιώντας τη μέθοδο \textit{fit}.

%Αφού εκπαιδευτεί, το μοντέλο χρησιμοποιείται για προβλέψεις στο σύνολο δοκιμών, και η απόδοσή του αξιολογείται μέσω της ακρίβειας (\textit{accuracy}), και του F1 Score ενώ απεικονίζεται μέσω του πίνακα σύγχυσης (\textit{confusion matrix}). Ο πίνακας σύγχυσης, ο οποίος καταγράφει τα σωστά και λανθασμένα αποτελέσματα ανά κατηγορία, απεικονίζεται γραφικά με τη χρήση της βιβλιοθήκης \textit{seaborn}. Το F1 Score παρέχει μια συνολική μέτρηση της απόδοσης του μοντέλου, συνδυάζοντας την ακρίβεια (\textit{precision}) και την ανάκληση (\textit{recall}). Η συγκεκριμένη μεθοδολογία εξασφαλίζει μια ολοκληρωμένη αξιολόγηση της ικανότητας του μοντέλου να ταξινομεί σωστά τα δεδομένα, εστιάζοντας τόσο στη συνολική ακρίβεια όσο και στην ισορροπημένη απόδοση ανάμεσα στις κατηγορίες.

\subsection{XGBoost Regression}

Αυτή η υλοποίηση του XGBoost περιλαμβάνει τη χρήση του RandomizedSearchCV για τη βελτιστοποίηση των υπερπαραμέτρων του μοντέλου. Αρχικά, ορίζεται μια κατανομή παραμέτρων που περιλαμβάνει επιλογές όπως το πλήθος των δέντρων (n_estimators), το βάθος τους (max_depth), τον ρυθμό εκμάθησης (learning_rate), και άλλες παραμέτρους όπως το subsample και το gamma. Στη συνέχεια, το RandomizedSearchCV εκτελεί 25 τυχαίες δοκιμές (n_iter=25) με 5-πτυχή διασταυρούμενη επικύρωση (cv=5), βελτιστοποιώντας τη μέτρηση F1 score.


\chapter{Πειραματικά Αποτελέσματα - Ερμηνεία}

Στο κεφάλαιο αυτό περιγράφεται η υλοποίηση των μοντέλων πρόβλεψης, παρουσιάζονται τα αποτελέσματά εκτέλεσής τους όσον αφορά την ποιότητα της πρόβλεψης, καθώς και τα συμπεράσματα που προέκυψαν από την αξιολόγησή τους.







\chapter{Επίλογος} 



\selectlanguage{greek}


%%% Bibliography

% You shouldn't want to include all the contents of thesis.bib
% in your bibliography (do you?)


\bibliographystyle{plainnat}
\bibliography{thesis}



%%%  End of document
\end{document}
